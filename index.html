<!DOCTYPE HTML>
<html>
<head>
    <title>how 2 spek gud</title>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
    <link href="speech.css" rel="stylesheet" type="text/css"/>
    <link href="https://fonts.googleapis.com/css?family=Montez" rel="stylesheet">
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <script src = "bundle.js"></script>
</head>
<body>
    <div id="container">
        <div class="decor">
            <div class="polygon"></div>
        </div>
        <h1>how to spek gud</h1>
        <input type="submit" id="submitBtn" class="btn btn-info" value="Submit Button">
        <div class="row">
        <div class="col-sm-4">
            <h3>Column 2</h3>
            <p>Lorem ipsum dolor sit amet, consectetur adipisicing elit...</p>
        </div>
        <div class="col-sm-4">
            <h3>Column 2</h3>
            <p>Lorem ipsum dolor sit amet, consectetur adipisicing elit...</p>
        </div>
        <div class="col-sm-4">
            <h3>Column 2</h3>
            <p>Lorem ipsum dolor sit amet, consectetur adipisicing elit...</p>
        </div>
        </div>
    </div>
    <div id="contents">
        <div id="footer">
            <footer>not &copy; JJC</footer>
        </div>
    </div>

    <script src="speech.js"></script>
    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>
        
        <div id="warning">
        <h1 style="font-weight:500;">Speech Recognition SDK not found.</h1>
        <h2 style="font-weight:500;">Please execute <code>npm run bundle</code> and reload.</h2>
            
    </div>
    <div id="content" style="display:none">
        <table width="100%">
            <tr>
                <input id="key" style="display:none" type="text" size="40" value="30f9e601bedb4f59916b6fd7f3d20624">
            </tr>
            
            <tr>
                <td></td>
                <td>
                    <button id="startBtn" disabled="disabled">Start</button>
                    <button id="stopBtn" disabled="disabled">Stop</button>
                    <input type="file" id="filePicker" accept=".wav" style="display:none"/>
                </td>
            </tr>
            <tr>
                <td></td>
                <td>
                    <table>
                        <tr>
                            <td>Results:</td>
                            <td>Current hypothesis:</td>
                        </tr>
                        <tr>
                            <td>
                                <textarea id="phraseDiv" style="display: inline-block;width:500px;height:200px"></textarea>
                            </td>
                            <td style="vertical-align: top">
                                <span id="hypothesisDiv" style="width:200px;height:200px;display:block;"></span>
                            </td>
                        </tr>
                    </table>
                </td>
            </tr>
            <tr>
                <td align="right">Status:</td>
                <td align="left"><span id="statusDiv"></span></td>
            </tr>
        </table>
    </div>

    <!-- SDK REFERENCE -->
    <script src="../../distrib/speech.sdk.bundle.js"></script>

    
    <script src='https://code.responsivevoice.org/responsivevoice.js'></script>
    
    <script>
        // Example 4: implements app actions.
        //var prompt = require('prompt-sync')();
        var ConversationV1 = require('watson-developer-cloud/conversation/v1');
        var endConversation = false;
    
            
        // Set up Conversation service wrapper.
        window.conversation = new ConversationV1({
          username: '62c028a8-814f-499f-92b7-cd19884de4ac', // replace with service username
          password: 'aXVgNhLkOPYL', // replace with service password
          version_date: '2017-05-26',
        });

        var workspace_id = 'c84df8e6-af10-45b5-9c09-4d5355dd74e7'; // replace with workspace ID

        // Start conversation with empty message.
        conversation.message({
          workspace_id: workspace_id
          }, processResponse);

        // Process the conversation response.
        function processResponse(err, response) {
          window.watResponse = response;
            
          if (err) {
            console.error(err); // something went wrong
            return;
          }

           endConversation = false;

          // Check for action flags.
          if (response.output.action === 'display_time') {
            // User asked what time it is, so we output the local system time.
            console.log('The current time is ' + new Date().toLocaleTimeString());
          } else if (response.output.action === 'close') {
            // User said goodbye, so we're done.
            responsiveVoice.speak(response.output.text[0], "UK English Female", {rate: 0.85});
            endConversation = true;
          } else {
            // Display the output from dialog, if any.
            if (response.output.text.length != 0) {
                responsiveVoice.speak(response.output.text[0], "UK English Female", {rate: 0.85});
            }
          }
        }
    </script>
    
    
    
    
    <!-- SDK USAGE -->
    <script>
     //   var newMessageFromUser;
        // On document load resolve the SDK dependency
        function Initialize(onComplete) {
            if (!!window.SDK) {
                document.getElementById('content').style.display = 'block';
                document.getElementById('warning').style.display = 'none';
                onComplete(window.SDK);
            }
        }
        
        // Setup the recognizer
        function RecognizerSetup(SDK, recognitionMode, language, format, subscriptionKey) {
            
                    recognitionMode = SDK.RecognitionMode.Dictation; 

            var recognizerConfig = new SDK.RecognizerConfig(
                new SDK.SpeechConfig(
                    new SDK.Context(
                        new SDK.OS(navigator.userAgent, "Browser", null),
                        new SDK.Device("SpeechSample", "SpeechSample", "1.0.00000"))),
                recognitionMode,
                language, // Supported languages are specific to each recognition mode. Refer to docs.
                format); // SDK.SpeechResultFormat.Simple (Options - Simple/Detailed)


            var useTokenAuth = false;
            
            var authentication = function() {
                if (!useTokenAuth)
                    return new SDK.CognitiveSubscriptionKeyAuthentication(subscriptionKey);

                var callback = function() {
                    var tokenDeferral = new SDK.Deferred();
                    try {
                        var xhr = new(XMLHttpRequest || ActiveXObject)('MSXML2.XMLHTTP.3.0');
                        xhr.open('GET', '/token', 1);
                        xhr.onload = function () {
                            if (xhr.status === 200)  {
                                tokenDeferral.Resolve(xhr.responseText);
                            } else {
                                tokenDeferral.Reject('Issue token request failed.');
                            }
                        };
                        xhr.send();
                    } catch (e) {
                        window.console && console.log(e);
                        tokenDeferral.Reject(e.message);
                    }
                    return tokenDeferral.Promise();
                }

                return new SDK.CognitiveTokenAuthentication(callback, callback);
            }();
            
            var files = document.getElementById('filePicker').files;
            if (!files.length) {
                return SDK.CreateRecognizer(recognizerConfig, authentication);
            } else {
                return SDK.CreateRecognizerWithFileAudioSource(recognizerConfig, authentication, files[0]);
            }
        }

        // Start the recognition
        function RecognizerStart(SDK, recognizer) {
            recognizer.Recognize((event) => {
                /*
                 Alternative syntax for typescript devs.
                 if (event instanceof SDK.RecognitionTriggeredEvent)
                */
                switch (event.Name) {
                    case "RecognitionTriggeredEvent" :
                        UpdateStatus("Initializing");
                        break;
                    case "ListeningStartedEvent" :
                        UpdateStatus("Listening");
                        break;
                    case "RecognitionStartedEvent" :
                        UpdateStatus("Listening_Recognizing");
                        break;
                    case "SpeechStartDetectedEvent" :
                        UpdateStatus("Listening_DetectedSpeech_Recognizing");
                        console.log(JSON.stringify(event.Result)); // check console for other information in result
                        break;
                    case "SpeechHypothesisEvent" :
                        UpdateRecognizedHypothesis(event.Result.Text, false);
                        console.log(JSON.stringify(event.Result)); // check console for other information in result
                        break;
                    case "SpeechFragmentEvent" :
                        UpdateRecognizedHypothesis(event.Result.Text, true);
                        console.log(JSON.stringify(event.Result)); // check console for other information in result
                        break;
//                    case "SpeechEndDetectedEvent" :
//                        OnSpeechEndDetected();
//                        UpdateStatus("Processing_Adding_Final_Touches");
//                        console.log(JSON.stringify(event.Result)); // check console for other information in result
//                        break;
                    case "SpeechSimplePhraseEvent" :
                        UpdateRecognizedPhrase(JSON.stringify(event.Result, null, 3));
                        break;
                    case "RecognitionEndedEvent" :
                        OnComplete();
                        UpdateStatus("Idle");
                        console.log(JSON.stringify(event)); // Debug information
                        break;
                    default:
                        console.log(JSON.stringify(event)); // Debug information
                }
            })
            .On(() => {
                // The request succeeded. Nothing to do here.
            },
            (error) => {
                console.error(error);
            });
        }

        // Stop the Recognition.
        function RecognizerStop(SDK, recognizer) {
            // recognizer.AudioSource.Detach(audioNodeId) can be also used here. (audioNodeId is part of ListeningStartedEvent)
            recognizer.AudioSource.TurnOff();
            
            //window.alert(phraseDiv.innerHTML);
            var conversation = window.conversation
            
            var newMessageFromUser=phraseDiv.innerHTML;
            newMessageFromUser = newMessageFromUser.replace(/(\r\n|\n|\r)/gm,"");
           // alert(response.output);
              // If we're not done, prompt for the next round of input.
            //  if (!endConversation) {
                 // alert(conversation.message);
                conversation.message({
                  workspace_id: 'c84df8e6-af10-45b5-9c09-4d5355dd74e7',
                  input: { text: newMessageFromUser },
                  // Send back the context to maintain state.
               //   context :  window.watResponse.context,
                }, processResponse)
            //  }
        }
    </script>

    <!-- Browser Hooks -->
    <script>
        var startBtn, stopBtn, hypothesisDiv, phraseDiv, statusDiv;
        var key, filePicker;
        var SDK;
        var recognizer;
        var previousSubscriptionKey;

        document.addEventListener("DOMContentLoaded", function () {
            createBtn = document.getElementById("createBtn");
            startBtn = document.getElementById("startBtn");
            stopBtn = document.getElementById("stopBtn");
            phraseDiv = document.getElementById("phraseDiv");
            hypothesisDiv = document.getElementById("hypothesisDiv");
            statusDiv = document.getElementById("statusDiv");
            key = document.getElementById("key");
            filePicker = document.getElementById('filePicker');

            startBtn.addEventListener("click", function () {
                if (key.value == "" || key.value == "YOUR_BING_SPEECH_API_KEY") {
                    alert("Please enter your Bing Speech subscription key!");
                    return;
                }
                if (!recognizer || previousSubscriptionKey != key.value) {
                    previousSubscriptionKey = key.value;
                    Setup();
                }

                hypothesisDiv.innerHTML = "";
                phraseDiv.innerHTML = "";
                RecognizerStart(SDK, recognizer);
                startBtn.disabled = true;
                stopBtn.disabled = false;
            });

            key.addEventListener("focus", function () {
               if (key.value == "YOUR_BING_SPEECH_API_KEY") {
                   key.value = "";
               }
            });

            key.addEventListener("focusout", function () {
               if (key.value == "") {
                   key.value = "YOUR_BING_SPEECH_API_KEY";
               }
            });

            stopBtn.addEventListener("click", function () {
                RecognizerStop(SDK, recognizer);
                startBtn.disabled = false;
                stopBtn.disabled = true;
            });

            Initialize(function (speechSdk) {
                SDK = speechSdk;
                startBtn.disabled = false;
            });
        });

        function Setup() {
            if (recognizer != null) {
                RecognizerStop(SDK, recognizer);
            }
            recognizer = RecognizerSetup(SDK, "Dictation", "en-US", SDK.SpeechResultFormat["Simple"], key.value);
        }

        function UpdateStatus(status) {
            statusDiv.innerHTML = status;
        }

        function UpdateRecognizedHypothesis(text, append) {
            if (append) 
                hypothesisDiv.innerHTML += text + " ";
            else 
                hypothesisDiv.innerHTML = text;

            var length = hypothesisDiv.innerHTML.length;
            if (length > 403) {
                hypothesisDiv.innerHTML = "..." + hypothesisDiv.innerHTML.substr(length-400, length);
            }
        }

        function OnSpeechEndDetected() {
            stopBtn.disabled = true;
        }

        function UpdateRecognizedPhrase(json) {
            hypothesisDiv.innerHTML = "";
            if (!(JSON.parse(json).DisplayText=== "undefined")) {
                phraseDiv.innerHTML += JSON.parse(json).DisplayText + "\n";
            }
        }

        function OnComplete() {
            startBtn.disabled = false;
            stopBtn.disabled = true;
        }
    </script>
</body>    
</html>